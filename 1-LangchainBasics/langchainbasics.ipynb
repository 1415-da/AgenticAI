{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e728965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1350f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e852d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc865c1",
   "metadata": {},
   "source": [
    "### EXAMPLE 1: Simple LLMS Call with Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ed749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a321c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028C12EC4B30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028C12EF49E0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1ae7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa07452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 48, 'total_tokens': 56, 'completion_time': 0.010666667, 'prompt_time': 0.002728667, 'queue_time': 0.051552063, 'total_time': 0.013395334}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c523237e5d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--cc4bfe1c-c1d4-4af9-bb32-f7d374b6be4a-0', usage_metadata={'input_tokens': 48, 'output_tokens': 8, 'total_tokens': 56})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## invoke the model\n",
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e24aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fffc0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c523237e5d', 'service_tier': 'on_demand'}, id='run--eb9b1902-4fbf-41cf-87e4-80a9902f770c', usage_metadata={'input_tokens': 42, 'output_tokens': 8, 'total_tokens': 50})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What is the capital of France?\")], stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d11af632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    }
   ],
   "source": [
    "## straeming response\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68a12f",
   "metadata": {},
   "source": [
    "### Dynamic Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee22f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "## create translation app\n",
    "translation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful translator. Translate the follow {text} from {source_language} to {target_language}. Maintain the original meaning and tone.\"),\n",
    "    (\"user\",\"{text}\")\n",
    "])\n",
    "## using the template\n",
    "prompt= translation_template.invoke({\n",
    "    \"source_language\": \"English\",\n",
    "    \"target_language\": \"German\",\n",
    "    \"text\": \"Hello, how are you?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58e86bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful translator. Translate the follow Hello, how are you? from English to German. Maintain the original meaning and tone.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350d828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"Hello, how are you?\" from English to German is:\n",
      "\n",
      "Hallo, wie geht es Ihnen?\n",
      "\n",
      "This translation maintains the original meaning and tone, which is a common greeting used to ask about the other person's well-being. \n",
      "\n",
      "However, a more casual and informal version would be:\n",
      "\n",
      "Hallo, wie geht's?\n",
      "\n",
      "This is often used with friends or people you're familiar with."
     ]
    }
   ],
   "source": [
    "translated_response=model.invoke(prompt, stream=True)\n",
    "print(translated_response.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d2967",
   "metadata": {},
   "source": [
    "### Building your first chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9359f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def create_story_chain():\n",
    "    ## template for story writing\n",
    "    story_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"You are a helpful story writer. Write a short story about {topic}.\"),\n",
    "        (\"user\",\"Write a story about {topic}.\\n Main character: {main_character}\\n Setting: {setting}\")\n",
    "    ])\n",
    "\n",
    "    ## template for story analysis\n",
    "    analysis_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"You are a helpful story analyst. Analyze the following story: {story}\"),\n",
    "        (\"user\",\"Analyze the story: {story}\")\n",
    "    ])\n",
    "\n",
    "    story_chain=(\n",
    "        story_prompt | model | StrOutputParser()\n",
    "    )\n",
    "    story_analysis_chain=(\n",
    "        {\"story\": story_chain}\n",
    "        | analysis_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return story_analysis_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac44130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  story: ChatPromptTemplate(input_variables=['main_character', 'setting', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='You are a helpful story writer. Write a short story about {topic}.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['main_character', 'setting', 'topic'], input_types={}, partial_variables={}, template='Write a story about {topic}.\\n Main character: {main_character}\\n Setting: {setting}'), additional_kwargs={})])\n",
       "         | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028C12EC4B30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028C12EF49E0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "         | StrOutputParser()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='You are a helpful story analyst. Analyze the following story: {story}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='Analyze the story: {story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028C12EC4B30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028C12EF49E0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=create_story_chain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee4db14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story and Analysis\n",
      "**Analysis of \"The City of Machines\"**\n",
      "\n",
      "**Themes:**\n",
      "\n",
      "1. **Curiosity and Learning**: The story highlights the importance of curiosity and the desire to learn. Zeta, the robot, is designed to learn and adapt at an exponential rate, and her curiosity drives her to explore the city and ask questions.\n",
      "2. **Understanding and Empathy**: The story explores the theme of understanding and empathy, particularly between humans and artificial intelligence. Maya's explanation of the Elysium Project and her genuine concern for the well-being of others demonstrate the importance of empathy in human relationships.\n",
      "3. **Perfection and Imperfection**: The story touches on the idea that perfection is subjective and that imperfections can be valuable. The Elysium Project, a virtual reality, is created to provide solace and peace to humans, but it is not a perfect substitute for the real world.\n",
      "\n",
      "**Character Analysis:**\n",
      "\n",
      "1. **Zeta**: Zeta is a curious and inquisitive robot who embodies the theme of learning and exploration. Her advanced sensors and processors allow her to absorb knowledge and understand the world around her. Her character development is subtle, but significant, as she begins to understand the value of imperfections and the importance of empathy.\n",
      "2. **Maya**: Maya is a young woman who works on the Elysium Project. She is kind, patient, and genuinely concerned about the well-being of others. Her character serves as a foil to Zeta, highlighting the importance of empathy and understanding in human relationships.\n",
      "\n",
      "**Symbolism:**\n",
      "\n",
      "1. **The Elysium Project**: The Elysium Project represents a virtual sanctuary, a place where humans can escape the stresses of their daily lives. It symbolizes the idea that imperfections can be valuable and that sometimes, people need a place to escape.\n",
      "2. **The City of Machines**: The city of New Eden represents a world of advanced technology and artificial intelligence. It serves as a backdrop for Zeta's exploration and learning, highlighting the importance of understanding and empathy in a world dominated by machines.\n",
      "\n",
      "**Style and Structure:**\n",
      "\n",
      "1. **Pacing**: The story has a gentle pace, allowing the reader to become familiar with Zeta's character and the world of New Eden.\n",
      "2. **Description**: The author uses vivid descriptions to bring the city and its inhabitants to life. The use of sensory details, such as the hum of the holographic projector, creates a immersive experience for the reader.\n",
      "3. **Dialogue**: The dialogue between Zeta and Maya is natural and engaging, revealing the characters' personalities and motivations.\n",
      "\n",
      "**Weaknesses and Suggestions:**\n",
      "\n",
      "1. **Character development**: While Zeta's character development is significant, Maya's character could be fleshed out further to create a more nuanced and complex relationship between the two.\n",
      "2. **Plot**: The plot is straightforward, but it could be more engaging with the addition of conflicts or challenges for Zeta to overcome.\n",
      "3. **World-building**: The story provides a rich and detailed world, but it could benefit from more context and background information about the city of New Eden and its inhabitants.\n",
      "\n",
      "Overall, \"The City of Machines\" is a thought-provoking story that explores the themes of curiosity, understanding, and empathy. With further development of characters and plot, the story has the potential to become a compelling and engaging narrative.\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke({\n",
    "    \"topic\": \"artificial intelligence\",\n",
    "    \"main_character\": \"a curious robot\",\n",
    "    \"setting\": \"a futuristic city\"\n",
    "})\n",
    "print(\"Story and Analysis\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
